{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler # Used for scaling of data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dettol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Outliers\n",
    "#train_df.sort_values(by = 'GrLivArea', ascending = False)[:2]\n",
    "#Deleting outliers\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 524].index)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "# Combine train and test, separate SalePrice from rest of train\n",
    "data_all = pd.concat([df_train,df_test],sort=False,ignore_index=True).drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 80)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = data_all.copy()\n",
    "\n",
    "for columnName in processed_df: # loop through columns\n",
    "    columnSeriesObj = processed_df[columnName]\n",
    "\n",
    "    if type(columnSeriesObj[0])==str or type(columnSeriesObj[0])==float: # find column with str or object\n",
    "        # create replacement list\n",
    "        uniq_value_of_col = []\n",
    "        uniq_value_of_col = processed_df[columnName].unique()\n",
    "        num_of_nums = len(uniq_value_of_col)\n",
    "        replacement_list =  np.arange(num_of_nums)\n",
    "\n",
    "        # replace elements of list\n",
    "        processed_df[columnName]=processed_df[columnName].replace(uniq_value_of_col, replacement_list) # replace elements in column\n",
    "    \n",
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2912</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2913</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2914</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2915</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2916</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2917 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0             60         0         65.0     8450       0      0         0   \n",
       "1             20         0         80.0     9600       0      0         0   \n",
       "2             60         0         68.0    11250       0      0         1   \n",
       "3             70         0         60.0     9550       0      0         1   \n",
       "4             60         0         84.0    14260       0      0         1   \n",
       "...          ...       ...          ...      ...     ...    ...       ...   \n",
       "2912         160         1         21.0     1936       0      0         0   \n",
       "2913         160         1         21.0     1894       0      0         0   \n",
       "2914          20         0        160.0    20000       0      0         0   \n",
       "2915          85         0         62.0    10441       0      0         0   \n",
       "2916          60         0         74.0     9627       0      0         0   \n",
       "\n",
       "      LandContour  Utilities  LotConfig  ...  ScreenPorch  PoolArea  PoolQC  \\\n",
       "0               0          0          0  ...            0         0       0   \n",
       "1               0          0          1  ...            0         0       0   \n",
       "2               0          0          0  ...            0         0       0   \n",
       "3               0          0          2  ...            0         0       0   \n",
       "4               0          0          1  ...            0         0       0   \n",
       "...           ...        ...        ...  ...          ...       ...     ...   \n",
       "2912            0          0          0  ...            0         0       0   \n",
       "2913            0          0          0  ...            0         0       0   \n",
       "2914            0          0          0  ...            0         0       0   \n",
       "2915            0          0          0  ...            0         0       0   \n",
       "2916            0          0          0  ...            0         0       0   \n",
       "\n",
       "      Fence  MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         0            0        0       2    2008         0              0  \n",
       "1         0            0        0       5    2007         0              0  \n",
       "2         0            0        0       9    2008         0              0  \n",
       "3         0            0        0       2    2006         0              1  \n",
       "4         0            0        0      12    2008         0              0  \n",
       "...     ...          ...      ...     ...     ...       ...            ...  \n",
       "2912      0            0        0       6    2006         0              0  \n",
       "2913      0            0        0       4    2006         0              1  \n",
       "2914      0            0        0       9    2006         0              1  \n",
       "2915      1            1      700       7    2006         0              0  \n",
       "2916      0            0        0      11    2006         0              0  \n",
       "\n",
       "[2917 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 2 columns with too any NaNs\n",
    "#processed_df=processed_df.drop(columns=['LotFrontage','PoolQC','MiscFeature','Alley','FireplaceQu','Fence','GarageYrBlt'])\n",
    "\n",
    "# Check for NaNs \n",
    "# findNaN = processed_df[processed_df.isna().any(axis=1)]\n",
    "\n",
    "# Drop pretty uncorrelated columns         \n",
    "#processed_df=processed_df.drop(columns=['YrSold','LowQualFinSF','MiscVal','BsmtHalfBath','BsmtFinSF2','3SsnPorch','MoSold'])\n",
    "processed_df=processed_df.drop(columns=['Id'])\n",
    "\n",
    "# Fill in stupid nan rows with mean..\n",
    "processed_df = processed_df.fillna(processed_df.dropna().median())\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = processed_df.values\n",
    "#train_df.shape\n",
    "\n",
    "df_train_processed = processed_df.iloc[:len(df_train),:]\n",
    "df_prediction_test_processed = processed_df.iloc[len(df_train):,:]\n",
    "\n",
    "#X_train = dataset[:len(train_df),1:]\n",
    "#X_test = dataset[len(train_df):,1:]\n",
    "#Y_train = train_df['SalePrice'].values\n",
    "\n",
    "# Always standard scale the data before using NN\n",
    "scale = StandardScaler()\n",
    "df_train_processed = scale.fit_transform(df_train_processed)\n",
    "# Y is just the 'SalePrice' column\n",
    "y = df_train['SalePrice'].values\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_processed, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncols = ['SalePrice','OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']\\ndf_train = df_train[cols]\\n# Create dummy values\\ndf_train = pd.get_dummies(df_train)\\n#filling NA's with the mean of the column:\\ndf_train = df_train.fillna(df_train.mean())\\n# Always standard scale the data before using NN\\nscale = StandardScaler()\\nX_train = df_train[['OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']]\\nX_train = scale.fit_transform(X_train)\\n# Y is just the 'SalePrice' column\\ny = df_train['SalePrice'].values\\nseed = 7\\nnp.random.seed(seed)\\n# split into 67% for train and 33% for test\\nX_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.33, random_state=seed)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cols = ['SalePrice','OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']\n",
    "df_train = df_train[cols]\n",
    "# Create dummy values\n",
    "df_train = pd.get_dummies(df_train)\n",
    "#filling NA's with the mean of the column:\n",
    "df_train = df_train.fillna(df_train.mean())\n",
    "# Always standard scale the data before using NN\n",
    "scale = StandardScaler()\n",
    "X_train = df_train[['OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']]\n",
    "X_train = scale.fit_transform(X_train)\n",
    "# Y is just the 'SalePrice' column\n",
    "y = df_train['SalePrice'].values\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.33, random_state=seed)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = processed_df.values\n",
    "#train_df.shape\n",
    "\n",
    "df_train_processed = processed_df.iloc[:len(df_train),:]\n",
    "df_prediction_test_processed = processed_df.iloc[len(df_train):,:]\n",
    "\n",
    "# Always standard scale the data before using NN\n",
    "scale = StandardScaler()\n",
    "df_train_processed = scale.fit_transform(df_train_processed)\n",
    "# Y is just the 'SalePrice' column\n",
    "y = df_train['SalePrice'].values\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_processed, y, test_size=0.33, random_state=seed)\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(40, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(optimizer ='adam', loss = 'mean_squared_logarithmic_error', \n",
    "              metrics =[metrics.msle])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 976 samples, validate on 482 samples\n",
      "Epoch 1/400\n",
      "976/976 [==============================] - 0s 358us/step - loss: 108.1966 - mean_squared_logarithmic_error: 108.1965 - val_loss: 76.9566 - val_mean_squared_logarithmic_error: 76.9566\n",
      "Epoch 2/400\n",
      "976/976 [==============================] - 0s 114us/step - loss: 57.1690 - mean_squared_logarithmic_error: 57.1690 - val_loss: 41.8186 - val_mean_squared_logarithmic_error: 41.8186\n",
      "Epoch 3/400\n",
      "976/976 [==============================] - 0s 98us/step - loss: 32.3857 - mean_squared_logarithmic_error: 32.3857 - val_loss: 25.1786 - val_mean_squared_logarithmic_error: 25.1786\n",
      "Epoch 4/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 20.1076 - mean_squared_logarithmic_error: 20.1076 - val_loss: 16.4119 - val_mean_squared_logarithmic_error: 16.4119\n",
      "Epoch 5/400\n",
      "976/976 [==============================] - 0s 97us/step - loss: 13.4138 - mean_squared_logarithmic_error: 13.4138 - val_loss: 11.3691 - val_mean_squared_logarithmic_error: 11.3691\n",
      "Epoch 6/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 9.3951 - mean_squared_logarithmic_error: 9.3951 - val_loss: 8.1649 - val_mean_squared_logarithmic_error: 8.1649\n",
      "Epoch 7/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 6.7571 - mean_squared_logarithmic_error: 6.7571 - val_loss: 5.9755 - val_mean_squared_logarithmic_error: 5.9755\n",
      "Epoch 8/400\n",
      "976/976 [==============================] - 0s 109us/step - loss: 4.9265 - mean_squared_logarithmic_error: 4.9265 - val_loss: 4.4216 - val_mean_squared_logarithmic_error: 4.4216\n",
      "Epoch 9/400\n",
      "976/976 [==============================] - 0s 99us/step - loss: 3.6190 - mean_squared_logarithmic_error: 3.6190 - val_loss: 3.2991 - val_mean_squared_logarithmic_error: 3.2991\n",
      "Epoch 10/400\n",
      "976/976 [==============================] - 0s 101us/step - loss: 2.6731 - mean_squared_logarithmic_error: 2.6731 - val_loss: 2.4778 - val_mean_squared_logarithmic_error: 2.4778\n",
      "Epoch 11/400\n",
      "976/976 [==============================] - 0s 103us/step - loss: 1.9832 - mean_squared_logarithmic_error: 1.9832 - val_loss: 1.8692 - val_mean_squared_logarithmic_error: 1.8692\n",
      "Epoch 12/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 1.4737 - mean_squared_logarithmic_error: 1.4737 - val_loss: 1.4178 - val_mean_squared_logarithmic_error: 1.4178\n",
      "Epoch 13/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 1.0919 - mean_squared_logarithmic_error: 1.0919 - val_loss: 1.0596 - val_mean_squared_logarithmic_error: 1.0596\n",
      "Epoch 14/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.7852 - mean_squared_logarithmic_error: 0.7852 - val_loss: 0.7699 - val_mean_squared_logarithmic_error: 0.7699\n",
      "Epoch 15/400\n",
      "976/976 [==============================] - 0s 104us/step - loss: 0.5513 - mean_squared_logarithmic_error: 0.5513 - val_loss: 0.5573 - val_mean_squared_logarithmic_error: 0.5573\n",
      "Epoch 16/400\n",
      "976/976 [==============================] - 0s 97us/step - loss: 0.3907 - mean_squared_logarithmic_error: 0.3907 - val_loss: 0.4131 - val_mean_squared_logarithmic_error: 0.4131\n",
      "Epoch 17/400\n",
      "976/976 [==============================] - 0s 107us/step - loss: 0.2860 - mean_squared_logarithmic_error: 0.2860 - val_loss: 0.3191 - val_mean_squared_logarithmic_error: 0.3191\n",
      "Epoch 18/400\n",
      "976/976 [==============================] - 0s 98us/step - loss: 0.2199 - mean_squared_logarithmic_error: 0.2199 - val_loss: 0.2578 - val_mean_squared_logarithmic_error: 0.2578\n",
      "Epoch 19/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.1787 - mean_squared_logarithmic_error: 0.1787 - val_loss: 0.2177 - val_mean_squared_logarithmic_error: 0.2177\n",
      "Epoch 20/400\n",
      "976/976 [==============================] - 0s 93us/step - loss: 0.1526 - mean_squared_logarithmic_error: 0.1526 - val_loss: 0.1914 - val_mean_squared_logarithmic_error: 0.1914\n",
      "Epoch 21/400\n",
      "976/976 [==============================] - 0s 103us/step - loss: 0.1354 - mean_squared_logarithmic_error: 0.1354 - val_loss: 0.1738 - val_mean_squared_logarithmic_error: 0.1738\n",
      "Epoch 22/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.1235 - mean_squared_logarithmic_error: 0.1235 - val_loss: 0.1614 - val_mean_squared_logarithmic_error: 0.1614\n",
      "Epoch 23/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.1148 - mean_squared_logarithmic_error: 0.1148 - val_loss: 0.1518 - val_mean_squared_logarithmic_error: 0.1518\n",
      "Epoch 24/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.1077 - mean_squared_logarithmic_error: 0.1077 - val_loss: 0.1449 - val_mean_squared_logarithmic_error: 0.1449\n",
      "Epoch 25/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.1017 - mean_squared_logarithmic_error: 0.1017 - val_loss: 0.1392 - val_mean_squared_logarithmic_error: 0.1392\n",
      "Epoch 26/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0965 - mean_squared_logarithmic_error: 0.0965 - val_loss: 0.1347 - val_mean_squared_logarithmic_error: 0.1347\n",
      "Epoch 27/400\n",
      "976/976 [==============================] - 0s 98us/step - loss: 0.0918 - mean_squared_logarithmic_error: 0.0918 - val_loss: 0.1304 - val_mean_squared_logarithmic_error: 0.1304\n",
      "Epoch 28/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.0876 - mean_squared_logarithmic_error: 0.0876 - val_loss: 0.1268 - val_mean_squared_logarithmic_error: 0.1268\n",
      "Epoch 29/400\n",
      "976/976 [==============================] - 0s 96us/step - loss: 0.0837 - mean_squared_logarithmic_error: 0.0837 - val_loss: 0.1239 - val_mean_squared_logarithmic_error: 0.1239\n",
      "Epoch 30/400\n",
      "976/976 [==============================] - 0s 96us/step - loss: 0.0802 - mean_squared_logarithmic_error: 0.0802 - val_loss: 0.1212 - val_mean_squared_logarithmic_error: 0.1212\n",
      "Epoch 31/400\n",
      "976/976 [==============================] - 0s 107us/step - loss: 0.0769 - mean_squared_logarithmic_error: 0.0769 - val_loss: 0.1188 - val_mean_squared_logarithmic_error: 0.1188\n",
      "Epoch 32/400\n",
      "976/976 [==============================] - 0s 96us/step - loss: 0.0739 - mean_squared_logarithmic_error: 0.0739 - val_loss: 0.1163 - val_mean_squared_logarithmic_error: 0.1163\n",
      "Epoch 33/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0710 - mean_squared_logarithmic_error: 0.0710 - val_loss: 0.1144 - val_mean_squared_logarithmic_error: 0.1144\n",
      "Epoch 34/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0683 - mean_squared_logarithmic_error: 0.0683 - val_loss: 0.1125 - val_mean_squared_logarithmic_error: 0.1125\n",
      "Epoch 35/400\n",
      "976/976 [==============================] - 0s 105us/step - loss: 0.0658 - mean_squared_logarithmic_error: 0.0658 - val_loss: 0.1107 - val_mean_squared_logarithmic_error: 0.1107\n",
      "Epoch 36/400\n",
      "976/976 [==============================] - 0s 104us/step - loss: 0.0635 - mean_squared_logarithmic_error: 0.0635 - val_loss: 0.1089 - val_mean_squared_logarithmic_error: 0.1089\n",
      "Epoch 37/400\n",
      "976/976 [==============================] - 0s 98us/step - loss: 0.0613 - mean_squared_logarithmic_error: 0.0613 - val_loss: 0.1074 - val_mean_squared_logarithmic_error: 0.1074\n",
      "Epoch 38/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0591 - mean_squared_logarithmic_error: 0.0591 - val_loss: 0.1058 - val_mean_squared_logarithmic_error: 0.1058\n",
      "Epoch 39/400\n",
      "976/976 [==============================] - 0s 94us/step - loss: 0.0572 - mean_squared_logarithmic_error: 0.0572 - val_loss: 0.1041 - val_mean_squared_logarithmic_error: 0.1041\n",
      "Epoch 40/400\n",
      "976/976 [==============================] - 0s 110us/step - loss: 0.0553 - mean_squared_logarithmic_error: 0.0553 - val_loss: 0.1031 - val_mean_squared_logarithmic_error: 0.1031\n",
      "Epoch 41/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0536 - mean_squared_logarithmic_error: 0.0536 - val_loss: 0.1012 - val_mean_squared_logarithmic_error: 0.1012\n",
      "Epoch 42/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0518 - mean_squared_logarithmic_error: 0.0518 - val_loss: 0.1000 - val_mean_squared_logarithmic_error: 0.1000\n",
      "Epoch 43/400\n",
      "976/976 [==============================] - 0s 97us/step - loss: 0.0502 - mean_squared_logarithmic_error: 0.0502 - val_loss: 0.0988 - val_mean_squared_logarithmic_error: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0487 - mean_squared_logarithmic_error: 0.0487 - val_loss: 0.0974 - val_mean_squared_logarithmic_error: 0.0974\n",
      "Epoch 45/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0473 - mean_squared_logarithmic_error: 0.0473 - val_loss: 0.0961 - val_mean_squared_logarithmic_error: 0.0961\n",
      "Epoch 46/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0460 - mean_squared_logarithmic_error: 0.0460 - val_loss: 0.0952 - val_mean_squared_logarithmic_error: 0.0952\n",
      "Epoch 47/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0447 - mean_squared_logarithmic_error: 0.0447 - val_loss: 0.0941 - val_mean_squared_logarithmic_error: 0.0941\n",
      "Epoch 48/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0434 - mean_squared_logarithmic_error: 0.0434 - val_loss: 0.0930 - val_mean_squared_logarithmic_error: 0.0930\n",
      "Epoch 49/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0423 - mean_squared_logarithmic_error: 0.0423 - val_loss: 0.0916 - val_mean_squared_logarithmic_error: 0.0916\n",
      "Epoch 50/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0411 - mean_squared_logarithmic_error: 0.0411 - val_loss: 0.0906 - val_mean_squared_logarithmic_error: 0.0906\n",
      "Epoch 51/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0401 - mean_squared_logarithmic_error: 0.0401 - val_loss: 0.0900 - val_mean_squared_logarithmic_error: 0.0900\n",
      "Epoch 52/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0391 - mean_squared_logarithmic_error: 0.0391 - val_loss: 0.0889 - val_mean_squared_logarithmic_error: 0.0889\n",
      "Epoch 53/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0382 - mean_squared_logarithmic_error: 0.0382 - val_loss: 0.0881 - val_mean_squared_logarithmic_error: 0.0881\n",
      "Epoch 54/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0372 - mean_squared_logarithmic_error: 0.0372 - val_loss: 0.0873 - val_mean_squared_logarithmic_error: 0.0873\n",
      "Epoch 55/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0364 - mean_squared_logarithmic_error: 0.0364 - val_loss: 0.0864 - val_mean_squared_logarithmic_error: 0.0864\n",
      "Epoch 56/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0355 - mean_squared_logarithmic_error: 0.0355 - val_loss: 0.0857 - val_mean_squared_logarithmic_error: 0.0857\n",
      "Epoch 57/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0347 - mean_squared_logarithmic_error: 0.0347 - val_loss: 0.0848 - val_mean_squared_logarithmic_error: 0.0848\n",
      "Epoch 58/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0339 - mean_squared_logarithmic_error: 0.0339 - val_loss: 0.0843 - val_mean_squared_logarithmic_error: 0.0843\n",
      "Epoch 59/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0332 - mean_squared_logarithmic_error: 0.0332 - val_loss: 0.0833 - val_mean_squared_logarithmic_error: 0.0833\n",
      "Epoch 60/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0325 - mean_squared_logarithmic_error: 0.0325 - val_loss: 0.0829 - val_mean_squared_logarithmic_error: 0.0829\n",
      "Epoch 61/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0318 - mean_squared_logarithmic_error: 0.0318 - val_loss: 0.0824 - val_mean_squared_logarithmic_error: 0.0824\n",
      "Epoch 62/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0311 - mean_squared_logarithmic_error: 0.0311 - val_loss: 0.0815 - val_mean_squared_logarithmic_error: 0.0815\n",
      "Epoch 63/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0305 - mean_squared_logarithmic_error: 0.0305 - val_loss: 0.0806 - val_mean_squared_logarithmic_error: 0.0806\n",
      "Epoch 64/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0298 - mean_squared_logarithmic_error: 0.0298 - val_loss: 0.0806 - val_mean_squared_logarithmic_error: 0.0806\n",
      "Epoch 65/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0292 - mean_squared_logarithmic_error: 0.0292 - val_loss: 0.0799 - val_mean_squared_logarithmic_error: 0.0799\n",
      "Epoch 66/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0287 - mean_squared_logarithmic_error: 0.0287 - val_loss: 0.0795 - val_mean_squared_logarithmic_error: 0.0795\n",
      "Epoch 67/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0281 - mean_squared_logarithmic_error: 0.0281 - val_loss: 0.0785 - val_mean_squared_logarithmic_error: 0.0785\n",
      "Epoch 68/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0276 - mean_squared_logarithmic_error: 0.0276 - val_loss: 0.0782 - val_mean_squared_logarithmic_error: 0.0782\n",
      "Epoch 69/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0271 - mean_squared_logarithmic_error: 0.0271 - val_loss: 0.0776 - val_mean_squared_logarithmic_error: 0.0776\n",
      "Epoch 70/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0265 - mean_squared_logarithmic_error: 0.0265 - val_loss: 0.0770 - val_mean_squared_logarithmic_error: 0.0770\n",
      "Epoch 71/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0260 - mean_squared_logarithmic_error: 0.0260 - val_loss: 0.0768 - val_mean_squared_logarithmic_error: 0.0768\n",
      "Epoch 72/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0255 - mean_squared_logarithmic_error: 0.0255 - val_loss: 0.0764 - val_mean_squared_logarithmic_error: 0.0764\n",
      "Epoch 73/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0251 - mean_squared_logarithmic_error: 0.0251 - val_loss: 0.0762 - val_mean_squared_logarithmic_error: 0.0762\n",
      "Epoch 74/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0246 - mean_squared_logarithmic_error: 0.0246 - val_loss: 0.0755 - val_mean_squared_logarithmic_error: 0.0755\n",
      "Epoch 75/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0241 - mean_squared_logarithmic_error: 0.0241 - val_loss: 0.0751 - val_mean_squared_logarithmic_error: 0.0751\n",
      "Epoch 76/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0237 - mean_squared_logarithmic_error: 0.0237 - val_loss: 0.0749 - val_mean_squared_logarithmic_error: 0.0749\n",
      "Epoch 77/400\n",
      "976/976 [==============================] - 0s 81us/step - loss: 0.0233 - mean_squared_logarithmic_error: 0.0233 - val_loss: 0.0747 - val_mean_squared_logarithmic_error: 0.0747\n",
      "Epoch 78/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0228 - mean_squared_logarithmic_error: 0.0228 - val_loss: 0.0743 - val_mean_squared_logarithmic_error: 0.0743\n",
      "Epoch 79/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0224 - mean_squared_logarithmic_error: 0.0224 - val_loss: 0.0741 - val_mean_squared_logarithmic_error: 0.0741\n",
      "Epoch 80/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0220 - mean_squared_logarithmic_error: 0.0220 - val_loss: 0.0741 - val_mean_squared_logarithmic_error: 0.0741\n",
      "Epoch 81/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0215 - mean_squared_logarithmic_error: 0.0215 - val_loss: 0.0737 - val_mean_squared_logarithmic_error: 0.0737\n",
      "Epoch 82/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0212 - mean_squared_logarithmic_error: 0.0212 - val_loss: 0.0731 - val_mean_squared_logarithmic_error: 0.0731\n",
      "Epoch 83/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0208 - mean_squared_logarithmic_error: 0.0208 - val_loss: 0.0728 - val_mean_squared_logarithmic_error: 0.0728\n",
      "Epoch 84/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0204 - mean_squared_logarithmic_error: 0.0204 - val_loss: 0.0724 - val_mean_squared_logarithmic_error: 0.0724\n",
      "Epoch 85/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0200 - mean_squared_logarithmic_error: 0.0200 - val_loss: 0.0727 - val_mean_squared_logarithmic_error: 0.0727\n",
      "Epoch 86/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0197 - mean_squared_logarithmic_error: 0.0197 - val_loss: 0.0725 - val_mean_squared_logarithmic_error: 0.0725\n",
      "Epoch 87/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 86us/step - loss: 0.0193 - mean_squared_logarithmic_error: 0.0193 - val_loss: 0.0722 - val_mean_squared_logarithmic_error: 0.0722\n",
      "Epoch 88/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.0190 - mean_squared_logarithmic_error: 0.0190 - val_loss: 0.0721 - val_mean_squared_logarithmic_error: 0.0721\n",
      "Epoch 89/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0186 - mean_squared_logarithmic_error: 0.0186 - val_loss: 0.0718 - val_mean_squared_logarithmic_error: 0.0718\n",
      "Epoch 90/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0183 - mean_squared_logarithmic_error: 0.0183 - val_loss: 0.0717 - val_mean_squared_logarithmic_error: 0.0717\n",
      "Epoch 91/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0179 - mean_squared_logarithmic_error: 0.0179 - val_loss: 0.0718 - val_mean_squared_logarithmic_error: 0.0718\n",
      "Epoch 92/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0177 - mean_squared_logarithmic_error: 0.0177 - val_loss: 0.0717 - val_mean_squared_logarithmic_error: 0.0717\n",
      "Epoch 93/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0173 - mean_squared_logarithmic_error: 0.0173 - val_loss: 0.0716 - val_mean_squared_logarithmic_error: 0.0716\n",
      "Epoch 94/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0170 - mean_squared_logarithmic_error: 0.0170 - val_loss: 0.0717 - val_mean_squared_logarithmic_error: 0.0717\n",
      "Epoch 95/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0167 - mean_squared_logarithmic_error: 0.0167 - val_loss: 0.0718 - val_mean_squared_logarithmic_error: 0.0718\n",
      "Epoch 96/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0164 - mean_squared_logarithmic_error: 0.0164 - val_loss: 0.0718 - val_mean_squared_logarithmic_error: 0.0718\n",
      "Epoch 97/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0161 - mean_squared_logarithmic_error: 0.0161 - val_loss: 0.0717 - val_mean_squared_logarithmic_error: 0.0717\n",
      "Epoch 98/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0158 - mean_squared_logarithmic_error: 0.0158 - val_loss: 0.0718 - val_mean_squared_logarithmic_error: 0.0718\n",
      "Epoch 99/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0156 - mean_squared_logarithmic_error: 0.0156 - val_loss: 0.0717 - val_mean_squared_logarithmic_error: 0.0717\n",
      "Epoch 100/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0720 - val_mean_squared_logarithmic_error: 0.0720\n",
      "Epoch 101/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0150 - mean_squared_logarithmic_error: 0.0150 - val_loss: 0.0723 - val_mean_squared_logarithmic_error: 0.0723\n",
      "Epoch 102/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0147 - mean_squared_logarithmic_error: 0.0147 - val_loss: 0.0723 - val_mean_squared_logarithmic_error: 0.0723\n",
      "Epoch 103/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0145 - mean_squared_logarithmic_error: 0.0145 - val_loss: 0.0724 - val_mean_squared_logarithmic_error: 0.0724\n",
      "Epoch 104/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0142 - mean_squared_logarithmic_error: 0.0142 - val_loss: 0.0725 - val_mean_squared_logarithmic_error: 0.0725\n",
      "Epoch 105/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0140 - mean_squared_logarithmic_error: 0.0140 - val_loss: 0.0731 - val_mean_squared_logarithmic_error: 0.0731\n",
      "Epoch 106/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0137 - mean_squared_logarithmic_error: 0.0137 - val_loss: 0.0730 - val_mean_squared_logarithmic_error: 0.0730\n",
      "Epoch 107/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0135 - mean_squared_logarithmic_error: 0.0135 - val_loss: 0.0726 - val_mean_squared_logarithmic_error: 0.0726\n",
      "Epoch 108/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0132 - mean_squared_logarithmic_error: 0.0132 - val_loss: 0.0722 - val_mean_squared_logarithmic_error: 0.0722\n",
      "Epoch 109/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0130 - mean_squared_logarithmic_error: 0.0130 - val_loss: 0.0721 - val_mean_squared_logarithmic_error: 0.0721\n",
      "Epoch 110/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0128 - mean_squared_logarithmic_error: 0.0128 - val_loss: 0.0718 - val_mean_squared_logarithmic_error: 0.0718\n",
      "Epoch 111/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0125 - mean_squared_logarithmic_error: 0.0125 - val_loss: 0.0716 - val_mean_squared_logarithmic_error: 0.0716\n",
      "Epoch 112/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0123 - mean_squared_logarithmic_error: 0.0123 - val_loss: 0.0712 - val_mean_squared_logarithmic_error: 0.0712\n",
      "Epoch 113/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0121 - mean_squared_logarithmic_error: 0.0121 - val_loss: 0.0712 - val_mean_squared_logarithmic_error: 0.0712\n",
      "Epoch 114/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0119 - mean_squared_logarithmic_error: 0.0119 - val_loss: 0.0709 - val_mean_squared_logarithmic_error: 0.0709\n",
      "Epoch 115/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0116 - mean_squared_logarithmic_error: 0.0116 - val_loss: 0.0703 - val_mean_squared_logarithmic_error: 0.0703\n",
      "Epoch 116/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0114 - mean_squared_logarithmic_error: 0.0114 - val_loss: 0.0706 - val_mean_squared_logarithmic_error: 0.0706\n",
      "Epoch 117/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0112 - mean_squared_logarithmic_error: 0.0112 - val_loss: 0.0696 - val_mean_squared_logarithmic_error: 0.0696\n",
      "Epoch 118/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0110 - mean_squared_logarithmic_error: 0.0110 - val_loss: 0.0693 - val_mean_squared_logarithmic_error: 0.0693\n",
      "Epoch 119/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0108 - mean_squared_logarithmic_error: 0.0108 - val_loss: 0.0693 - val_mean_squared_logarithmic_error: 0.0693\n",
      "Epoch 120/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0106 - mean_squared_logarithmic_error: 0.0106 - val_loss: 0.0697 - val_mean_squared_logarithmic_error: 0.0697\n",
      "Epoch 121/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0104 - mean_squared_logarithmic_error: 0.0104 - val_loss: 0.0689 - val_mean_squared_logarithmic_error: 0.0689\n",
      "Epoch 122/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0102 - mean_squared_logarithmic_error: 0.0102 - val_loss: 0.0692 - val_mean_squared_logarithmic_error: 0.0692\n",
      "Epoch 123/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0101 - mean_squared_logarithmic_error: 0.0101 - val_loss: 0.0681 - val_mean_squared_logarithmic_error: 0.0681\n",
      "Epoch 124/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0099 - mean_squared_logarithmic_error: 0.0099 - val_loss: 0.0686 - val_mean_squared_logarithmic_error: 0.0686\n",
      "Epoch 125/400\n",
      "976/976 [==============================] - 0s 80us/step - loss: 0.0097 - mean_squared_logarithmic_error: 0.0097 - val_loss: 0.0684 - val_mean_squared_logarithmic_error: 0.0684\n",
      "Epoch 126/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0095 - mean_squared_logarithmic_error: 0.0095 - val_loss: 0.0675 - val_mean_squared_logarithmic_error: 0.0675\n",
      "Epoch 127/400\n",
      "976/976 [==============================] - 0s 81us/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0678 - val_mean_squared_logarithmic_error: 0.0678\n",
      "Epoch 128/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0092 - mean_squared_logarithmic_error: 0.0092 - val_loss: 0.0677 - val_mean_squared_logarithmic_error: 0.0677\n",
      "Epoch 129/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0090 - mean_squared_logarithmic_error: 0.0090 - val_loss: 0.0673 - val_mean_squared_logarithmic_error: 0.0673\n",
      "Epoch 130/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 83us/step - loss: 0.0089 - mean_squared_logarithmic_error: 0.0089 - val_loss: 0.0672 - val_mean_squared_logarithmic_error: 0.0672\n",
      "Epoch 131/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0087 - mean_squared_logarithmic_error: 0.0087 - val_loss: 0.0674 - val_mean_squared_logarithmic_error: 0.0674\n",
      "Epoch 132/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0086 - mean_squared_logarithmic_error: 0.0086 - val_loss: 0.0667 - val_mean_squared_logarithmic_error: 0.0667\n",
      "Epoch 133/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0084 - mean_squared_logarithmic_error: 0.0084 - val_loss: 0.0668 - val_mean_squared_logarithmic_error: 0.0668\n",
      "Epoch 134/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0083 - mean_squared_logarithmic_error: 0.0083 - val_loss: 0.0663 - val_mean_squared_logarithmic_error: 0.0663\n",
      "Epoch 135/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0082 - mean_squared_logarithmic_error: 0.0082 - val_loss: 0.0665 - val_mean_squared_logarithmic_error: 0.0665\n",
      "Epoch 136/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0080 - mean_squared_logarithmic_error: 0.0080 - val_loss: 0.0664 - val_mean_squared_logarithmic_error: 0.0664\n",
      "Epoch 137/400\n",
      "976/976 [==============================] - 0s 81us/step - loss: 0.0079 - mean_squared_logarithmic_error: 0.0079 - val_loss: 0.0663 - val_mean_squared_logarithmic_error: 0.0663\n",
      "Epoch 138/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0078 - mean_squared_logarithmic_error: 0.0078 - val_loss: 0.0658 - val_mean_squared_logarithmic_error: 0.0658\n",
      "Epoch 139/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0076 - mean_squared_logarithmic_error: 0.0076 - val_loss: 0.0656 - val_mean_squared_logarithmic_error: 0.0656\n",
      "Epoch 140/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0075 - mean_squared_logarithmic_error: 0.0075 - val_loss: 0.0659 - val_mean_squared_logarithmic_error: 0.0659\n",
      "Epoch 141/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0074 - mean_squared_logarithmic_error: 0.0074 - val_loss: 0.0656 - val_mean_squared_logarithmic_error: 0.0656\n",
      "Epoch 142/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0072 - mean_squared_logarithmic_error: 0.0072 - val_loss: 0.0655 - val_mean_squared_logarithmic_error: 0.0655\n",
      "Epoch 143/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0071 - mean_squared_logarithmic_error: 0.0071 - val_loss: 0.0652 - val_mean_squared_logarithmic_error: 0.0652\n",
      "Epoch 144/400\n",
      "976/976 [==============================] - 0s 96us/step - loss: 0.0070 - mean_squared_logarithmic_error: 0.0070 - val_loss: 0.0652 - val_mean_squared_logarithmic_error: 0.0652\n",
      "Epoch 145/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0069 - mean_squared_logarithmic_error: 0.0069 - val_loss: 0.0648 - val_mean_squared_logarithmic_error: 0.0648\n",
      "Epoch 146/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0068 - mean_squared_logarithmic_error: 0.0068 - val_loss: 0.0654 - val_mean_squared_logarithmic_error: 0.0654\n",
      "Epoch 147/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0067 - mean_squared_logarithmic_error: 0.0067 - val_loss: 0.0653 - val_mean_squared_logarithmic_error: 0.0653\n",
      "Epoch 148/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0066 - mean_squared_logarithmic_error: 0.0066 - val_loss: 0.0650 - val_mean_squared_logarithmic_error: 0.0650\n",
      "Epoch 149/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0649 - val_mean_squared_logarithmic_error: 0.0649\n",
      "Epoch 150/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0064 - mean_squared_logarithmic_error: 0.0064 - val_loss: 0.0646 - val_mean_squared_logarithmic_error: 0.0646\n",
      "Epoch 151/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0063 - mean_squared_logarithmic_error: 0.0063 - val_loss: 0.0643 - val_mean_squared_logarithmic_error: 0.0643\n",
      "Epoch 152/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0062 - mean_squared_logarithmic_error: 0.0062 - val_loss: 0.0645 - val_mean_squared_logarithmic_error: 0.0645\n",
      "Epoch 153/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0061 - mean_squared_logarithmic_error: 0.0061 - val_loss: 0.0648 - val_mean_squared_logarithmic_error: 0.0648\n",
      "Epoch 154/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0060 - mean_squared_logarithmic_error: 0.0060 - val_loss: 0.0643 - val_mean_squared_logarithmic_error: 0.0643\n",
      "Epoch 155/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0059 - mean_squared_logarithmic_error: 0.0059 - val_loss: 0.0640 - val_mean_squared_logarithmic_error: 0.0640\n",
      "Epoch 156/400\n",
      "976/976 [==============================] - 0s 93us/step - loss: 0.0058 - mean_squared_logarithmic_error: 0.0058 - val_loss: 0.0638 - val_mean_squared_logarithmic_error: 0.0638\n",
      "Epoch 157/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0057 - mean_squared_logarithmic_error: 0.0057 - val_loss: 0.0639 - val_mean_squared_logarithmic_error: 0.0639\n",
      "Epoch 158/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0056 - mean_squared_logarithmic_error: 0.0056 - val_loss: 0.0639 - val_mean_squared_logarithmic_error: 0.0639\n",
      "Epoch 159/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0056 - mean_squared_logarithmic_error: 0.0056 - val_loss: 0.0644 - val_mean_squared_logarithmic_error: 0.0644\n",
      "Epoch 160/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0055 - mean_squared_logarithmic_error: 0.0055 - val_loss: 0.0642 - val_mean_squared_logarithmic_error: 0.0642\n",
      "Epoch 161/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0054 - mean_squared_logarithmic_error: 0.0054 - val_loss: 0.0634 - val_mean_squared_logarithmic_error: 0.0634\n",
      "Epoch 162/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0053 - mean_squared_logarithmic_error: 0.0053 - val_loss: 0.0641 - val_mean_squared_logarithmic_error: 0.0641\n",
      "Epoch 163/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0052 - mean_squared_logarithmic_error: 0.0052 - val_loss: 0.0643 - val_mean_squared_logarithmic_error: 0.0643\n",
      "Epoch 164/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0052 - mean_squared_logarithmic_error: 0.0052 - val_loss: 0.0634 - val_mean_squared_logarithmic_error: 0.0634\n",
      "Epoch 165/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0051 - mean_squared_logarithmic_error: 0.0051 - val_loss: 0.0638 - val_mean_squared_logarithmic_error: 0.0638\n",
      "Epoch 166/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0051 - mean_squared_logarithmic_error: 0.0051 - val_loss: 0.0636 - val_mean_squared_logarithmic_error: 0.0636\n",
      "Epoch 167/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0049 - mean_squared_logarithmic_error: 0.0049 - val_loss: 0.0639 - val_mean_squared_logarithmic_error: 0.0639\n",
      "Epoch 168/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0049 - mean_squared_logarithmic_error: 0.0049 - val_loss: 0.0637 - val_mean_squared_logarithmic_error: 0.0637\n",
      "Epoch 169/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0049 - mean_squared_logarithmic_error: 0.0049 - val_loss: 0.0639 - val_mean_squared_logarithmic_error: 0.0639\n",
      "Epoch 170/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0048 - mean_squared_logarithmic_error: 0.0048 - val_loss: 0.0635 - val_mean_squared_logarithmic_error: 0.0635\n",
      "Epoch 171/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0047 - mean_squared_logarithmic_error: 0.0047 - val_loss: 0.0633 - val_mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 172/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0046 - mean_squared_logarithmic_error: 0.0046 - val_loss: 0.0634 - val_mean_squared_logarithmic_error: 0.0634\n",
      "Epoch 173/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 90us/step - loss: 0.0046 - mean_squared_logarithmic_error: 0.0046 - val_loss: 0.0632 - val_mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 174/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0045 - mean_squared_logarithmic_error: 0.0045 - val_loss: 0.0632 - val_mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 175/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0044 - mean_squared_logarithmic_error: 0.0044 - val_loss: 0.0633 - val_mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 176/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0043 - mean_squared_logarithmic_error: 0.0043 - val_loss: 0.0635 - val_mean_squared_logarithmic_error: 0.0635\n",
      "Epoch 177/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0043 - mean_squared_logarithmic_error: 0.0043 - val_loss: 0.0633 - val_mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 178/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0634 - val_mean_squared_logarithmic_error: 0.0634\n",
      "Epoch 179/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0630 - val_mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 180/400\n",
      "976/976 [==============================] - 0s 97us/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0629 - val_mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 181/400\n",
      "976/976 [==============================] - 0s 94us/step - loss: 0.0041 - mean_squared_logarithmic_error: 0.0041 - val_loss: 0.0634 - val_mean_squared_logarithmic_error: 0.0634\n",
      "Epoch 182/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0040 - mean_squared_logarithmic_error: 0.0040 - val_loss: 0.0633 - val_mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 183/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0633 - val_mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 184/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0627 - val_mean_squared_logarithmic_error: 0.0627\n",
      "Epoch 185/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0629 - val_mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 186/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0630 - val_mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 187/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0628 - val_mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 188/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0037 - mean_squared_logarithmic_error: 0.0037 - val_loss: 0.0629 - val_mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 189/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0037 - mean_squared_logarithmic_error: 0.0037 - val_loss: 0.0625 - val_mean_squared_logarithmic_error: 0.0625\n",
      "Epoch 190/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0627 - val_mean_squared_logarithmic_error: 0.0627\n",
      "Epoch 191/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0035 - mean_squared_logarithmic_error: 0.0035 - val_loss: 0.0631 - val_mean_squared_logarithmic_error: 0.0631\n",
      "Epoch 192/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0630 - val_mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 193/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0035 - mean_squared_logarithmic_error: 0.0035 - val_loss: 0.0627 - val_mean_squared_logarithmic_error: 0.0627\n",
      "Epoch 194/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0627 - val_mean_squared_logarithmic_error: 0.0627\n",
      "Epoch 195/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0630 - val_mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 196/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0033 - mean_squared_logarithmic_error: 0.0033 - val_loss: 0.0626 - val_mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 197/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0033 - mean_squared_logarithmic_error: 0.0033 - val_loss: 0.0628 - val_mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 198/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0631 - val_mean_squared_logarithmic_error: 0.0631\n",
      "Epoch 199/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0630 - val_mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 200/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0628 - val_mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 201/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0629 - val_mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 202/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0031 - mean_squared_logarithmic_error: 0.0031 - val_loss: 0.0628 - val_mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 203/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0628 - val_mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 204/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0626 - val_mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 205/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0629 - val_mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 206/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0626 - val_mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 207/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0628 - val_mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 208/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0029 - mean_squared_logarithmic_error: 0.0029 - val_loss: 0.0625 - val_mean_squared_logarithmic_error: 0.0625\n",
      "Epoch 209/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0029 - mean_squared_logarithmic_error: 0.0029 - val_loss: 0.0613 - val_mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 210/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0028 - mean_squared_logarithmic_error: 0.0028 - val_loss: 0.0595 - val_mean_squared_logarithmic_error: 0.0595\n",
      "Epoch 211/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0028 - mean_squared_logarithmic_error: 0.0028 - val_loss: 0.0584 - val_mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 212/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0028 - mean_squared_logarithmic_error: 0.0028 - val_loss: 0.0571 - val_mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 213/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0027 - mean_squared_logarithmic_error: 0.0027 - val_loss: 0.0558 - val_mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 214/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0027 - mean_squared_logarithmic_error: 0.0027 - val_loss: 0.0550 - val_mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 215/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0027 - mean_squared_logarithmic_error: 0.0027 - val_loss: 0.0542 - val_mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 216/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 89us/step - loss: 0.0026 - mean_squared_logarithmic_error: 0.0026 - val_loss: 0.0528 - val_mean_squared_logarithmic_error: 0.0528\n",
      "Epoch 217/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0027 - mean_squared_logarithmic_error: 0.0027 - val_loss: 0.0521 - val_mean_squared_logarithmic_error: 0.0521\n",
      "Epoch 218/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0026 - mean_squared_logarithmic_error: 0.0026 - val_loss: 0.0519 - val_mean_squared_logarithmic_error: 0.0519\n",
      "Epoch 219/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0026 - mean_squared_logarithmic_error: 0.0026 - val_loss: 0.0514 - val_mean_squared_logarithmic_error: 0.0514\n",
      "Epoch 220/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.0025 - mean_squared_logarithmic_error: 0.0025 - val_loss: 0.0509 - val_mean_squared_logarithmic_error: 0.0509\n",
      "Epoch 221/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0025 - mean_squared_logarithmic_error: 0.0025 - val_loss: 0.0502 - val_mean_squared_logarithmic_error: 0.0502\n",
      "Epoch 222/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0025 - mean_squared_logarithmic_error: 0.0025 - val_loss: 0.0495 - val_mean_squared_logarithmic_error: 0.0495\n",
      "Epoch 223/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0024 - mean_squared_logarithmic_error: 0.0024 - val_loss: 0.0492 - val_mean_squared_logarithmic_error: 0.0492\n",
      "Epoch 224/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0024 - mean_squared_logarithmic_error: 0.0024 - val_loss: 0.0490 - val_mean_squared_logarithmic_error: 0.0490\n",
      "Epoch 225/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0024 - mean_squared_logarithmic_error: 0.0024 - val_loss: 0.0488 - val_mean_squared_logarithmic_error: 0.0488\n",
      "Epoch 226/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0025 - mean_squared_logarithmic_error: 0.0025 - val_loss: 0.0479 - val_mean_squared_logarithmic_error: 0.0479\n",
      "Epoch 227/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0025 - mean_squared_logarithmic_error: 0.0025 - val_loss: 0.0494 - val_mean_squared_logarithmic_error: 0.0494\n",
      "Epoch 228/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.0024 - mean_squared_logarithmic_error: 0.0024 - val_loss: 0.0486 - val_mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 229/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0023 - mean_squared_logarithmic_error: 0.0023 - val_loss: 0.0479 - val_mean_squared_logarithmic_error: 0.0479\n",
      "Epoch 230/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0023 - mean_squared_logarithmic_error: 0.0023 - val_loss: 0.0477 - val_mean_squared_logarithmic_error: 0.0477\n",
      "Epoch 231/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0022 - mean_squared_logarithmic_error: 0.0022 - val_loss: 0.0476 - val_mean_squared_logarithmic_error: 0.0476\n",
      "Epoch 232/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0022 - mean_squared_logarithmic_error: 0.0022 - val_loss: 0.0472 - val_mean_squared_logarithmic_error: 0.0472\n",
      "Epoch 233/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0022 - mean_squared_logarithmic_error: 0.0022 - val_loss: 0.0466 - val_mean_squared_logarithmic_error: 0.0466\n",
      "Epoch 234/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0022 - mean_squared_logarithmic_error: 0.0022 - val_loss: 0.0454 - val_mean_squared_logarithmic_error: 0.0454\n",
      "Epoch 235/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0021 - mean_squared_logarithmic_error: 0.0021 - val_loss: 0.0453 - val_mean_squared_logarithmic_error: 0.0453\n",
      "Epoch 236/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0021 - mean_squared_logarithmic_error: 0.0021 - val_loss: 0.0443 - val_mean_squared_logarithmic_error: 0.0443\n",
      "Epoch 237/400\n",
      "976/976 [==============================] - 0s 94us/step - loss: 0.0022 - mean_squared_logarithmic_error: 0.0022 - val_loss: 0.0444 - val_mean_squared_logarithmic_error: 0.0444\n",
      "Epoch 238/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0021 - mean_squared_logarithmic_error: 0.0021 - val_loss: 0.0438 - val_mean_squared_logarithmic_error: 0.0438\n",
      "Epoch 239/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0021 - mean_squared_logarithmic_error: 0.0021 - val_loss: 0.0437 - val_mean_squared_logarithmic_error: 0.0437\n",
      "Epoch 240/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0021 - mean_squared_logarithmic_error: 0.0021 - val_loss: 0.0427 - val_mean_squared_logarithmic_error: 0.0427\n",
      "Epoch 241/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0021 - mean_squared_logarithmic_error: 0.0021 - val_loss: 0.0429 - val_mean_squared_logarithmic_error: 0.0429\n",
      "Epoch 242/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0420 - val_mean_squared_logarithmic_error: 0.0420\n",
      "Epoch 243/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0413 - val_mean_squared_logarithmic_error: 0.0413\n",
      "Epoch 244/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0411 - val_mean_squared_logarithmic_error: 0.0411\n",
      "Epoch 245/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0406 - val_mean_squared_logarithmic_error: 0.0406\n",
      "Epoch 246/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0404 - val_mean_squared_logarithmic_error: 0.0404\n",
      "Epoch 247/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0019 - mean_squared_logarithmic_error: 0.0019 - val_loss: 0.0399 - val_mean_squared_logarithmic_error: 0.0399\n",
      "Epoch 248/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0397 - val_mean_squared_logarithmic_error: 0.0397\n",
      "Epoch 249/400\n",
      "976/976 [==============================] - 0s 93us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0394 - val_mean_squared_logarithmic_error: 0.0394\n",
      "Epoch 250/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0390 - val_mean_squared_logarithmic_error: 0.0390\n",
      "Epoch 251/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0387 - val_mean_squared_logarithmic_error: 0.0387\n",
      "Epoch 252/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0019 - mean_squared_logarithmic_error: 0.0019 - val_loss: 0.0388 - val_mean_squared_logarithmic_error: 0.0388\n",
      "Epoch 253/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0020 - mean_squared_logarithmic_error: 0.0020 - val_loss: 0.0379 - val_mean_squared_logarithmic_error: 0.0379\n",
      "Epoch 254/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0019 - mean_squared_logarithmic_error: 0.0019 - val_loss: 0.0384 - val_mean_squared_logarithmic_error: 0.0384\n",
      "Epoch 255/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0019 - mean_squared_logarithmic_error: 0.0019 - val_loss: 0.0379 - val_mean_squared_logarithmic_error: 0.0379\n",
      "Epoch 256/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0018 - mean_squared_logarithmic_error: 0.0018 - val_loss: 0.0378 - val_mean_squared_logarithmic_error: 0.0378\n",
      "Epoch 257/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.0018 - mean_squared_logarithmic_error: 0.0018 - val_loss: 0.0377 - val_mean_squared_logarithmic_error: 0.0377\n",
      "Epoch 258/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0018 - mean_squared_logarithmic_error: 0.0018 - val_loss: 0.0376 - val_mean_squared_logarithmic_error: 0.0376\n",
      "Epoch 259/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 86us/step - loss: 0.0018 - mean_squared_logarithmic_error: 0.0018 - val_loss: 0.0370 - val_mean_squared_logarithmic_error: 0.0370\n",
      "Epoch 260/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0018 - mean_squared_logarithmic_error: 0.0018 - val_loss: 0.0373 - val_mean_squared_logarithmic_error: 0.0373\n",
      "Epoch 261/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0019 - mean_squared_logarithmic_error: 0.0019 - val_loss: 0.0374 - val_mean_squared_logarithmic_error: 0.0374\n",
      "Epoch 262/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0019 - mean_squared_logarithmic_error: 0.0019 - val_loss: 0.0370 - val_mean_squared_logarithmic_error: 0.0370\n",
      "Epoch 263/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0019 - mean_squared_logarithmic_error: 0.0019 - val_loss: 0.0370 - val_mean_squared_logarithmic_error: 0.0370\n",
      "Epoch 264/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0017 - mean_squared_logarithmic_error: 0.0017 - val_loss: 0.0369 - val_mean_squared_logarithmic_error: 0.0369\n",
      "Epoch 265/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0017 - mean_squared_logarithmic_error: 0.0017 - val_loss: 0.0370 - val_mean_squared_logarithmic_error: 0.0370\n",
      "Epoch 266/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0017 - mean_squared_logarithmic_error: 0.0017 - val_loss: 0.0366 - val_mean_squared_logarithmic_error: 0.0366\n",
      "Epoch 267/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0365 - val_mean_squared_logarithmic_error: 0.0365\n",
      "Epoch 268/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0364 - val_mean_squared_logarithmic_error: 0.0364\n",
      "Epoch 269/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0364 - val_mean_squared_logarithmic_error: 0.0364\n",
      "Epoch 270/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0017 - mean_squared_logarithmic_error: 0.0017 - val_loss: 0.0359 - val_mean_squared_logarithmic_error: 0.0359\n",
      "Epoch 271/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0361 - val_mean_squared_logarithmic_error: 0.0361\n",
      "Epoch 272/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0360 - val_mean_squared_logarithmic_error: 0.0360\n",
      "Epoch 273/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0357 - val_mean_squared_logarithmic_error: 0.0357\n",
      "Epoch 274/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0017 - mean_squared_logarithmic_error: 0.0017 - val_loss: 0.0359 - val_mean_squared_logarithmic_error: 0.0359\n",
      "Epoch 275/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0358 - val_mean_squared_logarithmic_error: 0.0358\n",
      "Epoch 276/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0359 - val_mean_squared_logarithmic_error: 0.0359\n",
      "Epoch 277/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0359 - val_mean_squared_logarithmic_error: 0.0359\n",
      "Epoch 278/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0358 - val_mean_squared_logarithmic_error: 0.0358\n",
      "Epoch 279/400\n",
      "976/976 [==============================] - 0s 94us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 280/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0355 - val_mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 281/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0355 - val_mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 282/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 283/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0017 - mean_squared_logarithmic_error: 0.0017 - val_loss: 0.0352 - val_mean_squared_logarithmic_error: 0.0352\n",
      "Epoch 284/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 285/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 286/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 287/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0015 - mean_squared_logarithmic_error: 0.0015 - val_loss: 0.0352 - val_mean_squared_logarithmic_error: 0.0352\n",
      "Epoch 288/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0355 - val_mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 289/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 290/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0014 - mean_squared_logarithmic_error: 0.0014 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 291/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 292/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 293/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 294/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0354 - val_mean_squared_logarithmic_error: 0.0354\n",
      "Epoch 295/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0348 - val_mean_squared_logarithmic_error: 0.0348\n",
      "Epoch 296/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 297/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 298/400\n",
      "976/976 [==============================] - 0s 97us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 299/400\n",
      "976/976 [==============================] - 0s 100us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 300/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0354 - val_mean_squared_logarithmic_error: 0.0354\n",
      "Epoch 301/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0348 - val_mean_squared_logarithmic_error: 0.0348\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 88us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 303/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0353 - val_mean_squared_logarithmic_error: 0.0353\n",
      "Epoch 304/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 305/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 306/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 307/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 308/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0347 - val_mean_squared_logarithmic_error: 0.0347\n",
      "Epoch 309/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 310/400\n",
      "976/976 [==============================] - 0s 105us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0346 - val_mean_squared_logarithmic_error: 0.0346\n",
      "Epoch 311/400\n",
      "976/976 [==============================] - 0s 93us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 312/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 313/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 314/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 315/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 316/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0348 - val_mean_squared_logarithmic_error: 0.0348\n",
      "Epoch 317/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 318/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0345 - val_mean_squared_logarithmic_error: 0.0345\n",
      "Epoch 319/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 320/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 321/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0346 - val_mean_squared_logarithmic_error: 0.0346\n",
      "Epoch 322/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 323/400\n",
      "976/976 [==============================] - 0s 96us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0344 - val_mean_squared_logarithmic_error: 0.0344\n",
      "Epoch 324/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0347 - val_mean_squared_logarithmic_error: 0.0347\n",
      "Epoch 325/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0348 - val_mean_squared_logarithmic_error: 0.0348\n",
      "Epoch 326/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.0010 - mean_squared_logarithmic_error: 0.0010 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 327/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 328/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0010 - mean_squared_logarithmic_error: 0.0010 - val_loss: 0.0349 - val_mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 329/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0352 - val_mean_squared_logarithmic_error: 0.0352\n",
      "Epoch 330/400\n",
      "976/976 [==============================] - 0s 90us/step - loss: 0.0013 - mean_squared_logarithmic_error: 0.0013 - val_loss: 0.0350 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 331/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 0.0014 - mean_squared_logarithmic_error: 0.0014 - val_loss: 0.0355 - val_mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 332/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0348 - val_mean_squared_logarithmic_error: 0.0348\n",
      "Epoch 333/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 334/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 335/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 336/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0352 - val_mean_squared_logarithmic_error: 0.0352\n",
      "Epoch 337/400\n",
      "976/976 [==============================] - 0s 94us/step - loss: 0.0010 - mean_squared_logarithmic_error: 0.0010 - val_loss: 0.0355 - val_mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 338/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 0.0010 - mean_squared_logarithmic_error: 0.0010 - val_loss: 0.0354 - val_mean_squared_logarithmic_error: 0.0354\n",
      "Epoch 339/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0355 - val_mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 340/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0012 - mean_squared_logarithmic_error: 0.0012 - val_loss: 0.0351 - val_mean_squared_logarithmic_error: 0.0351\n",
      "Epoch 341/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0016 - mean_squared_logarithmic_error: 0.0016 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 342/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 343/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 9.9309e-04 - mean_squared_logarithmic_error: 9.9309e-04 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 344/400\n",
      "976/976 [==============================] - 0s 102us/step - loss: 9.8607e-04 - mean_squared_logarithmic_error: 9.8607e-04 - val_loss: 0.0354 - val_mean_squared_logarithmic_error: 0.0354\n",
      "Epoch 345/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 100us/step - loss: 9.0967e-04 - mean_squared_logarithmic_error: 9.0967e-04 - val_loss: 0.0355 - val_mean_squared_logarithmic_error: 0.0355\n",
      "Epoch 346/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 8.7406e-04 - mean_squared_logarithmic_error: 8.7406e-04 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 347/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 8.7936e-04 - mean_squared_logarithmic_error: 8.7936e-04 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 348/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 8.9306e-04 - mean_squared_logarithmic_error: 8.9306e-04 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 349/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 8.7775e-04 - mean_squared_logarithmic_error: 8.7775e-04 - val_loss: 0.0357 - val_mean_squared_logarithmic_error: 0.0357\n",
      "Epoch 350/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 8.7198e-04 - mean_squared_logarithmic_error: 8.7198e-04 - val_loss: 0.0356 - val_mean_squared_logarithmic_error: 0.0356\n",
      "Epoch 351/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 8.7882e-04 - mean_squared_logarithmic_error: 8.7882e-04 - val_loss: 0.0359 - val_mean_squared_logarithmic_error: 0.0359\n",
      "Epoch 352/400\n",
      "976/976 [==============================] - 0s 101us/step - loss: 9.6319e-04 - mean_squared_logarithmic_error: 9.6319e-04 - val_loss: 0.0360 - val_mean_squared_logarithmic_error: 0.0360\n",
      "Epoch 353/400\n",
      "976/976 [==============================] - 0s 102us/step - loss: 8.8454e-04 - mean_squared_logarithmic_error: 8.8454e-04 - val_loss: 0.0361 - val_mean_squared_logarithmic_error: 0.0361\n",
      "Epoch 354/400\n",
      "976/976 [==============================] - 0s 104us/step - loss: 8.9774e-04 - mean_squared_logarithmic_error: 8.9774e-04 - val_loss: 0.0361 - val_mean_squared_logarithmic_error: 0.0361\n",
      "Epoch 355/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 9.3127e-04 - mean_squared_logarithmic_error: 9.3127e-04 - val_loss: 0.0364 - val_mean_squared_logarithmic_error: 0.0364\n",
      "Epoch 356/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 9.7687e-04 - mean_squared_logarithmic_error: 9.7687e-04 - val_loss: 0.0362 - val_mean_squared_logarithmic_error: 0.0362\n",
      "Epoch 357/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 9.0050e-04 - mean_squared_logarithmic_error: 9.0050e-04 - val_loss: 0.0362 - val_mean_squared_logarithmic_error: 0.0362\n",
      "Epoch 358/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 9.2102e-04 - mean_squared_logarithmic_error: 9.2102e-04 - val_loss: 0.0362 - val_mean_squared_logarithmic_error: 0.0362\n",
      "Epoch 359/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 8.8127e-04 - mean_squared_logarithmic_error: 8.8127e-04 - val_loss: 0.0363 - val_mean_squared_logarithmic_error: 0.0363\n",
      "Epoch 360/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 0.0010 - mean_squared_logarithmic_error: 0.0010 - val_loss: 0.0360 - val_mean_squared_logarithmic_error: 0.0360\n",
      "Epoch 361/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 9.5750e-04 - mean_squared_logarithmic_error: 9.5750e-04 - val_loss: 0.0362 - val_mean_squared_logarithmic_error: 0.0362\n",
      "Epoch 362/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0362 - val_mean_squared_logarithmic_error: 0.0362\n",
      "Epoch 363/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 8.6646e-04 - mean_squared_logarithmic_error: 8.6646e-04 - val_loss: 0.0362 - val_mean_squared_logarithmic_error: 0.0362\n",
      "Epoch 364/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 8.0850e-04 - mean_squared_logarithmic_error: 8.0850e-04 - val_loss: 0.0368 - val_mean_squared_logarithmic_error: 0.0368\n",
      "Epoch 365/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 8.5674e-04 - mean_squared_logarithmic_error: 8.5674e-04 - val_loss: 0.0362 - val_mean_squared_logarithmic_error: 0.0362\n",
      "Epoch 366/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 8.3368e-04 - mean_squared_logarithmic_error: 8.3368e-04 - val_loss: 0.0365 - val_mean_squared_logarithmic_error: 0.0365\n",
      "Epoch 367/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 7.7702e-04 - mean_squared_logarithmic_error: 7.7702e-04 - val_loss: 0.0365 - val_mean_squared_logarithmic_error: 0.0365\n",
      "Epoch 368/400\n",
      "976/976 [==============================] - 0s 92us/step - loss: 7.7836e-04 - mean_squared_logarithmic_error: 7.7836e-04 - val_loss: 0.0365 - val_mean_squared_logarithmic_error: 0.0365\n",
      "Epoch 369/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 7.9623e-04 - mean_squared_logarithmic_error: 7.9623e-04 - val_loss: 0.0367 - val_mean_squared_logarithmic_error: 0.0367\n",
      "Epoch 370/400\n",
      "976/976 [==============================] - 0s 85us/step - loss: 8.4285e-04 - mean_squared_logarithmic_error: 8.4285e-04 - val_loss: 0.0373 - val_mean_squared_logarithmic_error: 0.0373\n",
      "Epoch 371/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 8.5901e-04 - mean_squared_logarithmic_error: 8.5901e-04 - val_loss: 0.0368 - val_mean_squared_logarithmic_error: 0.0368\n",
      "Epoch 372/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 8.6382e-04 - mean_squared_logarithmic_error: 8.6382e-04 - val_loss: 0.0368 - val_mean_squared_logarithmic_error: 0.0368\n",
      "Epoch 373/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 9.2196e-04 - mean_squared_logarithmic_error: 9.2196e-04 - val_loss: 0.0370 - val_mean_squared_logarithmic_error: 0.0370\n",
      "Epoch 374/400\n",
      "976/976 [==============================] - 0s 82us/step - loss: 0.0010 - mean_squared_logarithmic_error: 0.0010 - val_loss: 0.0372 - val_mean_squared_logarithmic_error: 0.0372\n",
      "Epoch 375/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0369 - val_mean_squared_logarithmic_error: 0.0369\n",
      "Epoch 376/400\n",
      "976/976 [==============================] - 0s 87us/step - loss: 8.9987e-04 - mean_squared_logarithmic_error: 8.9987e-04 - val_loss: 0.0371 - val_mean_squared_logarithmic_error: 0.0371\n",
      "Epoch 377/400\n",
      "976/976 [==============================] - 0s 93us/step - loss: 8.4880e-04 - mean_squared_logarithmic_error: 8.4880e-04 - val_loss: 0.0369 - val_mean_squared_logarithmic_error: 0.0369\n",
      "Epoch 378/400\n",
      "976/976 [==============================] - 0s 105us/step - loss: 7.9613e-04 - mean_squared_logarithmic_error: 7.9613e-04 - val_loss: 0.0372 - val_mean_squared_logarithmic_error: 0.0372\n",
      "Epoch 379/400\n",
      "976/976 [==============================] - 0s 91us/step - loss: 8.1229e-04 - mean_squared_logarithmic_error: 8.1229e-04 - val_loss: 0.0369 - val_mean_squared_logarithmic_error: 0.0369\n",
      "Epoch 380/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 7.2750e-04 - mean_squared_logarithmic_error: 7.2750e-04 - val_loss: 0.0374 - val_mean_squared_logarithmic_error: 0.0374\n",
      "Epoch 381/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 7.0854e-04 - mean_squared_logarithmic_error: 7.0854e-04 - val_loss: 0.0372 - val_mean_squared_logarithmic_error: 0.0372\n",
      "Epoch 382/400\n",
      "976/976 [==============================] - 0s 81us/step - loss: 7.6004e-04 - mean_squared_logarithmic_error: 7.6004e-04 - val_loss: 0.0375 - val_mean_squared_logarithmic_error: 0.0375\n",
      "Epoch 383/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 7.0640e-04 - mean_squared_logarithmic_error: 7.0640e-04 - val_loss: 0.0374 - val_mean_squared_logarithmic_error: 0.0374\n",
      "Epoch 384/400\n",
      "976/976 [==============================] - 0s 89us/step - loss: 6.7423e-04 - mean_squared_logarithmic_error: 6.7423e-04 - val_loss: 0.0374 - val_mean_squared_logarithmic_error: 0.0374\n",
      "Epoch 385/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 6.9089e-04 - mean_squared_logarithmic_error: 6.9089e-04 - val_loss: 0.0379 - val_mean_squared_logarithmic_error: 0.0379\n",
      "Epoch 386/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976/976 [==============================] - 0s 85us/step - loss: 7.2720e-04 - mean_squared_logarithmic_error: 7.2720e-04 - val_loss: 0.0374 - val_mean_squared_logarithmic_error: 0.0374\n",
      "Epoch 387/400\n",
      "976/976 [==============================] - 0s 93us/step - loss: 6.9044e-04 - mean_squared_logarithmic_error: 6.9044e-04 - val_loss: 0.0376 - val_mean_squared_logarithmic_error: 0.0376\n",
      "Epoch 388/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 7.1739e-04 - mean_squared_logarithmic_error: 7.1739e-04 - val_loss: 0.0374 - val_mean_squared_logarithmic_error: 0.0374\n",
      "Epoch 389/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 7.5205e-04 - mean_squared_logarithmic_error: 7.5205e-04 - val_loss: 0.0377 - val_mean_squared_logarithmic_error: 0.0377\n",
      "Epoch 390/400\n",
      "976/976 [==============================] - 0s 88us/step - loss: 7.7794e-04 - mean_squared_logarithmic_error: 7.7794e-04 - val_loss: 0.0385 - val_mean_squared_logarithmic_error: 0.0385\n",
      "Epoch 391/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 9.5269e-04 - mean_squared_logarithmic_error: 9.5269e-04 - val_loss: 0.0378 - val_mean_squared_logarithmic_error: 0.0378\n",
      "Epoch 392/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 9.5164e-04 - mean_squared_logarithmic_error: 9.5164e-04 - val_loss: 0.0382 - val_mean_squared_logarithmic_error: 0.0382\n",
      "Epoch 393/400\n",
      "976/976 [==============================] - 0s 94us/step - loss: 0.0010 - mean_squared_logarithmic_error: 0.0010 - val_loss: 0.0381 - val_mean_squared_logarithmic_error: 0.0381\n",
      "Epoch 394/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 8.6269e-04 - mean_squared_logarithmic_error: 8.6269e-04 - val_loss: 0.0382 - val_mean_squared_logarithmic_error: 0.0382\n",
      "Epoch 395/400\n",
      "976/976 [==============================] - 0s 95us/step - loss: 8.5443e-04 - mean_squared_logarithmic_error: 8.5443e-04 - val_loss: 0.0381 - val_mean_squared_logarithmic_error: 0.0381\n",
      "Epoch 396/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 8.9791e-04 - mean_squared_logarithmic_error: 8.9791e-04 - val_loss: 0.0388 - val_mean_squared_logarithmic_error: 0.0388\n",
      "Epoch 397/400\n",
      "976/976 [==============================] - 0s 84us/step - loss: 8.4457e-04 - mean_squared_logarithmic_error: 8.4457e-04 - val_loss: 0.0382 - val_mean_squared_logarithmic_error: 0.0382\n",
      "Epoch 398/400\n",
      "976/976 [==============================] - 0s 86us/step - loss: 8.6529e-04 - mean_squared_logarithmic_error: 8.6529e-04 - val_loss: 0.0388 - val_mean_squared_logarithmic_error: 0.0388\n",
      "Epoch 399/400\n",
      "976/976 [==============================] - 0s 83us/step - loss: 8.4681e-04 - mean_squared_logarithmic_error: 8.4681e-04 - val_loss: 0.0376 - val_mean_squared_logarithmic_error: 0.0376\n",
      "Epoch 400/400\n",
      "976/976 [==============================] - 0s 81us/step - loss: 0.0011 - mean_squared_logarithmic_error: 0.0011 - val_loss: 0.0383 - val_mean_squared_logarithmic_error: 0.0383\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=400, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5RddX338ffnTGYymSSQKxgSIMEC4gUDRITiY1FEuSiXaqkXLFZrrJcKbVWgfbx1PX0WPkuRalsQFY1CucilUEXLXaTcTCCVexOumSSQGJKQhEwyl+/zx/6dw5nhZHIyyTl7ZvbntdasOWfvfc7+zk7mfOb3++3924oIzMzMAEp5F2BmZsOHQ8HMzCocCmZmVuFQMDOzCoeCmZlVOBTMzKzCoWCFJenHkv5Pnds+I+ldja7JLG8OBTMzq3AomI1wksbkXYONHg4FG9ZSt80XJf1O0iZJP5S0p6RfStog6RZJk6u2P0nSI5LWSbpD0kFV6w6R9EB63ZVA+4B9vVfS4vTauyUdXGeNJ0p6UNJLkpZJ+tqA9W9L77curf9YWj5O0rckPStpvaS70rKjJXXWOA7vSo+/JulqSZdKegn4mKTDJd2T9rFS0j9Laqt6/Rsk3SzpRUkvSPo7Sa+R9LKkqVXbHSZptaTWen52G30cCjYSvB84FjgAeB/wS+DvgGlk/4c/DyDpAOBy4CxgOnAj8B+S2tIH5L8DPwWmAD9L70t67aHAJcCngKnA94AbJI2to75NwJ8Bk4ATgU9LOiW97z6p3u+mmuYCi9PrvgkcBvxhqulLQF+dx+Rk4Oq0z8uAXuCv0zE5EjgG+EyqYSJwC/ArYC/gD4BbI+J54A7gtKr3PR24IiK666zDRhmHgo0E342IFyJiOfAb4L6IeDAitgDXAYek7f4U+EVE3Jw+1L4JjCP70D0CaAUuiIjuiLga+G3VPj4JfC8i7ouI3ohYAGxJrxtURNwREQ9FRF9E/I4smP4orf4IcEtEXJ72uyYiFksqAR8HzoyI5Wmfd6efqR73RMS/p31ujohFEXFvRPRExDNkoVau4b3A8xHxrYjoiogNEXFfWreALAiQ1AJ8iCw4raAcCjYSvFD1eHON5xPS472AZ8srIqIPWAbMTOuWR/8ZIJ+terwv8Lep+2WdpHXA3ul1g5L0Vkm3p26X9cBfkv3FTnqPJ2u8bBpZ91WtdfVYNqCGAyT9XNLzqUvp/9ZRA8D1wOsl7UfWGlsfEfcPsSYbBRwKNpqsIPtwB0CSyD4QlwMrgZlpWdk+VY+XAf8YEZOqvjoi4vI69vtvwA3A3hGxO3ARUN7PMuC1NV7ze6BrG+s2AR1VP0cLWddTtYHTG18IPA7sHxG7kXWvba8GIqILuIqsRfNR3EooPIeCjSZXASdKOiYNlP4tWRfQ3cA9QA/weUljJP0xcHjVa78P/GX6q1+SxqcB5Il17Hci8GJEdEk6HPhw1brLgHdJOi3td6qkuakVcwlwvqS9JLVIOjKNYfwP0J723wr8b2B7YxsTgZeAjZJeB3y6at3PgddIOkvSWEkTJb21av1PgI8BJwGX1vHz2ijmULBRIyKeIOsf/y7ZX+LvA94XEVsjYivwx2QffmvJxh+urXrtQrJxhX9O65embevxGeAfJG0AvkIWTuX3fQ44gSygXiQbZH5zWv0F4CGysY0XgW8ApYhYn97zB2StnE1Av7ORavgCWRhtIAu4K6tq2EDWNfQ+4HlgCfCOqvX/RTbA/UAaj7ACk2+yY2aSbgP+LSJ+kHctli+HglnBSXoLcDPZmMiGvOuxfLn7yKzAJC0gu4bhLAeCgVsKZmZWxS0FMzOrGNETaU2bNi1mz56ddxlmZiPKokWLfh8RA699AUZ4KMyePZuFCxfmXYaZ2Ygi6dltrXP3kZmZVTgUzMyswqFgZmYVI3pMoZbu7m46Ozvp6urKu5SGam9vZ9asWbS2+l4oZrbrjLpQ6OzsZOLEicyePZv+E2KOHhHBmjVr6OzsZM6cOXmXY2ajyKjrPurq6mLq1KmjNhAAJDF16tRR3xoys+YbdaEAjOpAKCvCz2hmzTcqQ2F7Nm3p4fn1XfR5ig8zs34KGQovb+1h1YYuGpEJ69at41//9V93+HUnnHAC69at2/UFmZntgEKGwit3Kdz1thUKvb29g77uxhtvZNKkSY0qy8ysLqPu7KMdE+zqgDjnnHN48sknmTt3Lq2trUyYMIEZM2awePFiHn30UU455RSWLVtGV1cXZ555JvPnzwdembJj48aNHH/88bztbW/j7rvvZubMmVx//fWMGzdul9ZpZlbLqA6Fr//HIzy64qVXLe/u7WNrTx8dY8fscCS8fq/d+Or73rDN9eeddx4PP/wwixcv5o477uDEE0/k4Ycfrpw6eskllzBlyhQ2b97MW97yFt7//vczderUfu+xZMkSLr/8cr7//e9z2mmncc0113D66afvYKVmZjtuVIfCcHD44Yf3u5bgO9/5Dtdddx0Ay5YtY8mSJa8KhTlz5jB37lwADjvsMJ555pmm1WtmxTaqQ2Fbf9H/fuMWVqzbzOtn7MaYlsYOq4wfP77y+I477uCWW27hnnvuoaOjg6OPPrrmtQZjx46tPG5paWHz5s0NrdHMrKyQA83lLqNGnJA6ceJENmyofVfD9evXM3nyZDo6Onj88ce59957G1CBmdnQjeqWQh6mTp3KUUcdxRvf+EbGjRvHnnvuWVl33HHHcdFFF3HwwQdz4IEHcsQRR+RYqZnZq43oezTPmzcvBt5k57HHHuOggw4a9HVrNm1h+drNHPSa3WgdM3IbS/X8rGZmA0laFBHzaq0buZ+IO6GR3UdmZiNZIUPBsWBmVlshQ8GRYGZWW8NCQdIlklZJerhq2RRJN0takr5PTssl6TuSlkr6naRDG1VXVkj67lQwM+unkS2FHwPHDVh2DnBrROwP3JqeAxwP7J++5gMXNrCuBs58ZGY2sjUsFCLiTuDFAYtPBhakxwuAU6qW/yQy9wKTJM1oVG2VGhu9AzOzEabZYwp7RsRKgPR9j7R8JrCsarvOtOxVJM2XtFDSwtWrVze02KEY6tTZABdccAEvv/zyLq7IzKx+w2WguVaPTs0/5CPi4oiYFxHzpk+fvst2tqs4FMxsJGv2Fc0vSJoREStT99CqtLwT2Ltqu1nAioZVkVKhEdftVU+dfeyxx7LHHntw1VVXsWXLFk499VS+/vWvs2nTJk477TQ6Ozvp7e3ly1/+Mi+88AIrVqzgHe94B9OmTeP222/f9cWZmW1Hs0PhBuAM4Lz0/fqq5Z+TdAXwVmB9uZtpp/zyHHj+oVctHt/Xx37dfbS1tcCO3uv4NW+C48/b5urqqbNvuukmrr76au6//34igpNOOok777yT1atXs9dee/GLX/wCyOZE2n333Tn//PO5/fbbmTZt2o7VZGa2izTylNTLgXuAAyV1SvoEWRgcK2kJcGx6DnAj8BSwFPg+8JlG1dVMN910EzfddBOHHHIIhx56KI8//jhLlizhTW96E7fccgtnn302v/nNb9h9993zLtXMDGhgSyEiPrSNVcfU2DaAz+7yIrbxF/3Lm7t5Zs0m/mCPCXS0Na6xFBGce+65fOpTn3rVukWLFnHjjTdy7rnn8u53v5uvfOUrDavDzKxew2WgubkaePFa9dTZ73nPe7jkkkvYuHEjAMuXL2fVqlWsWLGCjo4OTj/9dL7whS/wwAMPvOq1ZmZ5KOTU2Y28oLl66uzjjz+eD3/4wxx55JEATJgwgUsvvZSlS5fyxS9+kVKpRGtrKxdemF2rN3/+fI4//nhmzJjhgWYzy0Uhp87e0NXN07/fxGunT2D82JGbi54628yGwlNnD+BpLszMaitkKJSN3DaSmVljjMpQ2G6XmBp49VqTjORuPzMbvkZdKLS3t7NmzZpBPzRHevdRRLBmzRra29vzLsXMRpmRO8q6DbNmzaKzs5PBJsvb0tPH6g1b6H2xjfbWliZWt+u0t7cza9asvMsws1Fm1IVCa2src+bMGXSbRc+u5ZOX3c2Cjx/OIQcMbVI9M7PRaNR1H9WjlPqP+vrcL29mVq2QodCSUqHPg7VmZv0UMhRKKodCzoWYmQ0zhQyF8hmpbimYmfVXyFAotxR8rr+ZWX+FDgV3H5mZ9VfQUMi+u/vIzKy/QoaC3FIwM6upkKFQqkx95FQwM6tW0FDwdQpmZrUUOhR6+3IuxMxsmClkKPg6BTOz2goZCuVpLjymYGbWXyFDwdcpmJnVVtBQyL67+8jMrL9ChoKvUzAzq62QoeDrFMzMaitoKKSWgpsKZmb9FDsUnAlmZv3kEgqS/lrSI5IelnS5pHZJcyTdJ2mJpCsltTVs/+mn9kCzmVl/TQ8FSTOBzwPzIuKNQAvwQeAbwLcjYn9gLfCJRtXwyv0UGrUHM7ORKa/uozHAOEljgA5gJfBO4Oq0fgFwSqN2Xh5o7nUqmJn10/RQiIjlwDeB58jCYD2wCFgXET1ps05gZq3XS5ovaaGkhatXrx5SDZ4Qz8ystjy6jyYDJwNzgL2A8cDxNTat+YkdERdHxLyImDd9+vQh1eDuIzOz2vLoPnoX8HRErI6IbuBa4A+BSak7CWAWsKJRBVSuaPbpR2Zm/eQRCs8BR0jqUHZp8THAo8DtwAfSNmcA1zeqAJ+SamZWWx5jCveRDSg/ADyUargYOBv4G0lLganADxtVg1Yu5uMtv4Te7kbtwsxsRBqz/U12vYj4KvDVAYufAg5vxv71zJ18pfWnfLevYWe9mpmNSIW8ohm1ABB9vvWamVm1YoZCKQsFKmfAmpkZFDUU3FIwM6upmKFQKk9+1JtvHWZmw0wxQyG1FOhz95GZWbVihkIaU4hw95GZWbVihkKlpeDuIzOzasUMhdRSUDgUzMyqFTMU3FIwM6upmKGQzj4KtxTMzPopZihUWgoeaDYzq1bMUPCYgplZTcUMhXJLwaFgZtZPMUOhfJ2CB5rNzPopZiikloIcCmZm/RQzFMpzH7n7yMysn2KGQrml4GkuzMz6KWYolDzQbGZWSzFDoTKm4JaCmVm1YoZC5ToFT51tZlat0KHg7iMzs/7qCgVJ10g6UdLoCJHKxWvuPjIzq1bvh/yFwIeBJZLOk/S6BtbUeKmlUHJLwcysn7pCISJuiYiPAIcCzwA3S7pb0p9Lam1kgQ3hloKZWU11dwdJmgp8DPgL4EHgn8hC4uaGVNZIJd9PwcysljH1bCTpWuB1wE+B90XEyrTqSkkLG1Vcw8izpJqZ1VJXKAD/HBG31VoREfN2YT3Nkaa58BXNZmb91dt9dJCkSeUnkiZL+sxQdyppkqSrJT0u6TFJR0qaIulmSUvS98lDff/tF+CWgplZLfWGwicjYl35SUSsBT65E/v9J+BXEfE64M3AY8A5wK0RsT9wa3reGL5OwcyspnpDoSRJ5SeSWoC2oexQ0m7A24EfAkTE1hQ4JwML0mYLgFOG8v71FeEJ8czMaqk3FP4TuErSMZLeCVwO/GqI+9wPWA38SNKDkn4gaTywZ3kAO33fo9aLJc2XtFDSwtWrVw+tgvI0FzgUzMyq1RsKZwO3AZ8GPkvWvfOlIe5zDNmprBdGxCHAJnagqygiLo6IeRExb/r06UOrwGMKZmY11XX2UUT0kV3VfOEu2Gcn0BkR96XnV5OFwguSZkTESkkzgFW7YF+1+ewjM7Oa6p37aP90ttCjkp4qfw1lhxHxPLBM0oFp0THAo8ANwBlp2RnA9UN5/7p4TMHMrKZ6r1P4EfBV4NvAO4A/BzToKwb3V8BlktqAp9L7lcjGLT4BPAf8yU68/+BK7j4yM6ul3lAYFxG3SlJEPAt8TdJvyIJih0XEYqDWRW/HDOX9dljlJjsOBTOzavWGQleaNnuJpM8By9nG2UEjgs8+MjOrqd6zj84COoDPA4cBp/NK///II1+8ZmZWy3ZbCulCtdMi4ovARrL+/5EtnX3kWVLNzPrbbkshInqBw6qvaB4NemnxQLOZ2QD1jik8CFwv6WdkF5sBEBHXNqSqJgiVfJMdM7MB6g2FKcAa4J1VywIYsaHQR8ndR2ZmA9R7RfPIH0cYIFSi5FAwM+un3juv/YisZdBPRHx8l1fUJKEW8CmpZmb91Nt99POqx+3AqcCKXV9O8/RRQn0OBTOzavV2H11T/VzS5cAtDamoSUI++8jMbKB6L14baH9gn11ZSLOFSgiHgplZtXrHFDbQf0zhebJ7LIxYoRZKEfT1BaXSqLoEw8xsyOrtPprY6EKaTiVa1EdPX9DmUDAzA+q/n8Kpknavej5JUuPuodwEoRZa6KW371UnVZmZFVa9YwpfjYj15ScRsY4hTps9XGSh0Ee3z0AyM6uoNxRqbVfv6azDUpRaKNFHb69bCmZmZfWGwkJJ50t6raT9JH0bWNTIwhpOJVrIxhTMzCxTbyj8FbAVuBK4CtgMfLZRRTVDufuox91HZmYV9Z59tAk4p8G1NJey7qMedx+ZmVXUe/bRzZImVT2fLOk/G1dWE5Sy7iOffWRm9op6u4+mpTOOAIiItYzkezTj7iMzs1rqDYU+SZVpLSTNpsasqSOJ0tlHHmg2M3tFvaeV/j1wl6Rfp+dvB+Y3pqQmUQsthMcUzMyq1DvQ/CtJ88iCYDFwPdkZSCNXqYWS3FIwM6tW74R4fwGcCcwiC4UjgHvof3vOkSWNKfR6TMHMrKLeMYUzgbcAz0bEO4BDgNUNq6oZSmmg2d1HZmYV9YZCV0R0AUgaGxGPAwc2rqzGU6nkgWYzswHqHWjuTNcp/Dtws6S1jPDbcVJqZQy9DgUzsyr1DjSfmh5+TdLtwO7Ar3Zmx5JagIXA8oh4r6Q5wBXAFOAB4KMRsXVn9jGoliwUPKZgZvaKHb4dZ0T8OiJu2AUf2GcCj1U9/wbw7YjYH1gLfGIn339wLW200U23xxTMzCqGeo/mnSJpFnAi8IP0XGRnMl2dNlkANPQmPmppo1W+yY6ZWbVcQgG4APgSUO67mQqsi4ie9LwTmFnrhZLmS1ooaeHq1TtxAtSYNsbS7TEFM7MqTQ8FSe8FVkVE9f0Yat0kueandURcHBHzImLe9OnTh15HSxut9NDT6zEFM7OyPO6edhRwkqQTgHZgN7KWwyRJY1JrYRYNPrtJrWOzUHBLwcysoukthYg4NyJmRcRs4IPAbRHxEeB24ANpszPIptJoGLW00UaPxxTMzKrkNaZQy9nA30haSjbG8MNG7kxjxtKqXnp6era/sZlZQeTRfVQREXcAd6THTwGHN2vfpda2rIaexl0KYWY20gynlkJTacxYAKLXoWBmVlbYUCilUOjrdiiYmZUVNxRS9xG9W/ItxMxsGCluKFS6jxwKZmZlhQ8FerrzLcTMbBgpbCjQks4+8kCzmVlF4UNBPe4+MjMrK24ojCm3FNx9ZGZWVtxQSC2FPrcUzMwqChwK6ewjh4KZWUWBQ6EVgOh2KJiZlRU4FMrdRz77yMysrLihULlOwS0FM7Oy4oZCufvI1ymYmVUUOBQ8S6qZ2UAFDoWspSCPKZiZVRQ3FMpjCn0OBTOzsuKGQnmaC1/RbGZWUdxQKI0hEHJLwcysorihINGrVkoOBTOziuKGAtBbamVMXzd9fZF3KWZmw0LBQ6Gddraypacv71LMzIaFQodCz5gOOtTFlp7evEsxMxsWCh0KvWM6GM8WurrdUjAzg6KHQut4xrOZrm63FMzMoOCh0Nc6PnUfuaVgZgYFD4VoHZ+6j9xSMDODHEJB0t6Sbpf0mKRHJJ2Zlk+RdLOkJen75IYX05a1FBwKZmaZPFoKPcDfRsRBwBHAZyW9HjgHuDUi9gduTc8bq2084+miy91HZmZADqEQESsj4oH0eAPwGDATOBlYkDZbAJzS6FpKYycwni62bO1p9K7MzEaEXMcUJM0GDgHuA/aMiJWQBQewxzZeM1/SQkkLV69evVP7L7VPpFW9dHV17dT7mJmNFrmFgqQJwDXAWRHxUr2vi4iLI2JeRMybPn36TtUwtmM3ADZvWr9T72NmNlrkEgqSWskC4bKIuDYtfkHSjLR+BrCq0XWM7ZgIwJaXNzR6V2ZmI0IeZx8J+CHwWEScX7XqBuCM9PgM4PpG19I6LoXCprobKmZmo9qYHPZ5FPBR4CFJi9OyvwPOA66S9AngOeBPGl5J2wQAujc7FMzMIIdQiIi7AG1j9THNrIW28QD0dG1s6m7NzIarQl/RzNispdDX5ZaCmRkUPRTadwegtMVnH5mZQdFDoWMaAGO3rs25EDOz4aHYodA2nq0aS0e3Q8HMDIoeChKbWyczvncdEb5Ps5lZsUMB2NI2mcnxku++ZmaGQ4Ge9ilM1UusfXlr3qWYmeWu8KGg8dOYog2s2rAl71LMzHJX+FBo3W0PpvISz6/3TKlmZoUPhfZJezJOW3lx7Yt5l2JmlrvCh0LHlJkAbPp9Z86VmJnlr/ChUJoyG4C+tc/kWoeZ2XBQ+FBg0r4AtL60LOdCzMzy51CYOINuWul42d1HZmYOhVKJl9pnsHvXcnp6fQGbmRWbQwHYOnFvZvECnWs3512KmVmuHApAy/QDeK1WsvR5T6FtZsXmUAAmzD6UDm1hzXOP5l2KmVmuHApAxz6HALB1+eLtbGlmNro5FACmHUg3rbSuejjvSszMcuVQABjTxprdXseBWx5izUZPjGdmxeVQSHrnHM3BepLFS57JuxQzs9w4FJLpbz6OFgUrH/xV3qWYmeXGoZC07XsEL7VMZq/nfk5vn2/NaWbF5FAoaxnDi/udxNtiEXctfizvaszMcuFQqDLr2M/RomD9rd8kwq0FMyseh0KVMXscwNMzTuQ9G6/nv+6+M+9yzMyazqEwwOwPnc/LpQnsffOnePrpJ/Mux8ysqYZVKEg6TtITkpZKOiePGsbstgdd7/8Je/Ai4xccw+K7bsyjDDOzXIzJu4AySS3AvwDHAp3AbyXdEBFNn5Boxhv/iOfbfknvFR9h7i0f4pHfzGXr7KOZuNeBdEydReu4ibSObWfs2HZaxrShllZKpRKlUglJgOBV30s1lg1YJzX7RzUz62fYhAJwOLA0Ip4CkHQFcDKQyyx1rzngMF7+67u552ffYM9lN/KGJy6AJ/Ko5NX62H54RF3b1GN07que96mvnh1X3753/jWZoexrxw21viG9boiHornHfcft6L6ePeRsDjnpM7u8juEUCjOB6ntidgJvHbiRpPnAfIB99tmnoQV1TJzCkR//BhHn8WznMlYvf4rudSvo27KJ3u4t9PZsRb3dqK87na0URPRBROUrSI8J6OurbFdZRqC0rdKv47Z+KQNe2SYGrtn202xRDFj/6o22uWQbBVXXM6g6zuSq633qUN/7DP5z1bEy7WvHDe3nHOqx2fHXaUi7Gux/7CD7GtKuhnYs6jnuA7cYyr/V0CNkx/e125R9h7y3wQynUKh1PF91pCLiYuBigHnz5jXlvFFJ7Lv3Puy7d2NDyMwsb8NpoLkT2Lvq+SxgRU61mJkV0nAKhd8C+0uaI6kN+CBwQ841mZkVyrDpPoqIHkmfA/4TaAEuiYhHci7LzKxQhk0oAETEjYAvDDAzy8lw6j4yM7OcORTMzKzCoWBmZhUOBTMzq9BIvm+ApNXAs0N8+TTg97uwnF1luNYFw7c217VjXNeOGY117RsR02utGNGhsDMkLYyIeXnXMdBwrQuGb22ua8e4rh1TtLrcfWRmZhUOBTMzqyhyKFycdwHbMFzrguFbm+vaMa5rxxSqrsKOKZiZ2asVuaVgZmYDOBTMzKyikKEg6ThJT0haKumcnGt5RtJDkhZLWpiWTZF0s6Ql6fvkJtRxiaRVkh6uWlazDmW+k47f7yQd2uS6viZpeTpmiyWdULXu3FTXE5Le08C69pZ0u6THJD0i6cy0PNdjNkhduR4zSe2S7pf036mur6flcyTdl47XlWnafCSNTc+XpvWzG1HXdmr7saSnq47Z3LS8mf//WyQ9KOnn6Xnjj1dEFOqLbFruJ4H9gDbgv4HX51jPM8C0Acv+H3BOenwO8I0m1PF24FDg4e3VAZwA/JLsbnlHAPc1ua6vAV+ose3r07/nWGBO+nduaVBdM4BD0+OJwP+k/ed6zAapK9djln7uCelxK3BfOg5XAR9Myy8CPp0efwa4KD3+IHBlA/+Pbau2HwMfqLF9M////w3wb8DP0/OGH68ithQOB5ZGxFMRsRW4Ajg555oGOhlYkB4vAE5p9A4j4k7gxTrrOBn4SWTuBSZJmtHEurblZOCKiNgSEU8DS8n+vRtR18qIeCA93gA8Rnaf8VyP2SB1bUtTjln6uTemp63pK4B3Alen5QOPV/k4Xg0cI2not0AeWm3b0pR/S0mzgBOBH6TnognHq4ihMBNYVvW8k8F/aRotgJskLZI0Py3bMyJWQvZLDuyRU23bqmM4HMPPpab7JVXda7nUlZrqh5D9hTlsjtmAuiDnY5a6QhYDq4CbyVol6yKip8a+K3Wl9euBqY2oq1ZtEVE+Zv+Yjtm3JY0dWFuNunelC4AvAX3p+VSacLyKGAq10jPP83KPiohDgeOBz0p6e4611CvvY3gh8FpgLrAS+FZa3vS6JE0ArgHOioiXBtu0xrKG1VajrtyPWUT0RsRcsvuvHw4cNMi+m3q8BtYm6Y3AucDrgLcAU4Czm1WbpPcCqyJiUfXiQfa7y2oqYih0AntXPZ8FrMipFiJiRfq+CriO7JflhXJzNH1flVN526oj12MYES+kX+I+4Pu80t3R1LoktZJ98F4WEdemxbkfs1p1DZdjlmpZB9xB1h8/SVL5DpDV+67UldbvTv3diLuituNSV1xExBbgRzT3mB0FnCTpGbIu7neStRwafryKGAq/BfZPo/htZIMyN+RRiKTxkiaWHwPvBh5O9ZyRNjsDuD6P+gap4wbgz9JZGEcA68tdJs0woP/2VLJjVq7rg+lMjDnA/sD9DapBwA+BxyLi/KpVuR6zbdWV9zGTNF3SpPR4HPAusvGO24EPpM0GHq/ycfwAcFukUdQm1fZ4VbiLrO+++pg19N8yIs6NiFkRMZvsM+q2iPgIzThejRgxH+5fZGcP/A9ZnznbHLsAAAJkSURBVObf51jHfmRnfvw38Ei5FrK+wFuBJen7lCbUcjlZt0I32V8dn9hWHWRN1X9Jx+8hYF6T6/pp2u/v0i/DjKrt/z7V9QRwfAPrehtZ8/x3wOL0dULex2yQunI9ZsDBwINp/w8DX6n6HbifbID7Z8DYtLw9PV+a1u/XwH/LbdV2WzpmDwOX8soZSk37/5/2dzSvnH3U8OPlaS7MzKyiiN1HZma2DQ4FMzOrcCiYmVmFQ8HMzCocCmZmVuFQMMuJpKPLs1+aDRcOBTMzq3AomG2HpNPTfPuLJX0vTZ62UdK3JD0g6VZJ09O2cyXdmyZRu06v3E/hDyTdomzO/gckvTa9/QRJV0t6XNJljZoJ1KxeDgWzQUg6CPhTsokL5wK9wEeA8cADkU1m+Gvgq+klPwHOjoiDya52LS+/DPiXiHgz8IdkV2lDNovpWWT3NdiPbM4bs9yM2f4mZoV2DHAY8Nv0R/w4sknu+oAr0zaXAtdK2h2YFBG/TssXAD9L81vNjIjrACKiCyC93/0R0ZmeLwZmA3c1/scyq82hYDY4AQsi4tx+C6UvD9husPliBusS2lL1uBf/TlrO3H1kNrhbgQ9I2gMq92Del+x3pzxb5YeBuyJiPbBW0v9Kyz8K/Dqy+xl0SjolvcdYSR1N/SnM6uS/SswGERGPSvrfZHfHK5HN1vpZYBPwBkmLyO5y9afpJWcAF6UP/aeAP0/LPwp8T9I/pPf4kyb+GGZ18yypZkMgaWNETMi7DrNdzd1HZmZW4ZaCmZlVuKVgZmYVDgUzM6twKJiZWYVDwczMKhwKZmZW8f8BHhNPsUTnfUQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['mean_squared_logarithmic_error'])\n",
    "plt.plot(history.history['val_mean_squared_logarithmic_error'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_test = pd.read_csv('test.csv')\\ncols = ['OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']\\nid_col = df_test['Id'].values.tolist()\\ndf_test['GrLivArea'] = np.log1p(df_test['GrLivArea'])\\ndf_test = pd.get_dummies(df_test)\\ndf_test = df_test.fillna(df_test.mean())\\nX_test = df_test[cols].values\\n# Always standard scale the data before using NN\\nscale = StandardScaler()\\nX_test = scale.fit_transform(X_test)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_test = pd.read_csv('test.csv')\n",
    "cols = ['OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']\n",
    "id_col = df_test['Id'].values.tolist()\n",
    "df_test['GrLivArea'] = np.log1p(df_test['GrLivArea'])\n",
    "df_test = pd.get_dummies(df_test)\n",
    "df_test = df_test.fillna(df_test.mean())\n",
    "X_test = df_test[cols].values\n",
    "# Always standard scale the data before using NN\n",
    "scale = StandardScaler()\n",
    "X_test = scale.fit_transform(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_prediction_test_processed\n",
    "X_test = df_test.values\n",
    "# Always standard scale the data before using NN\n",
    "scale = StandardScaler()\n",
    "X_test = scale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92122.78],\n",
       "       [434511.4 ],\n",
       "       [182048.55],\n",
       "       ...,\n",
       "       [186264.69],\n",
       "       [ 72234.94],\n",
       "       [255255.02]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col_df = pd.read_csv('test.csv')\n",
    "id_col = id_col_df['Id'].values.tolist()\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = id_col\n",
    "submission['SalePrice'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': conda)",
   "language": "python",
   "name": "python37464bitanaconda3condad70ad12a74794b86bb86e405b41bbd28"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
